{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQJvktBKMc9I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSoiuPL5J11f"
      },
      "outputs": [],
      "source": [
        "pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI-Dgx7daL7c"
      },
      "outputs": [],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "lUI27WHaJFTE",
        "outputId": "5e4441f2-0ae7-4780-f2d6-3f3806caed27"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"avnishkr/topics_in_ai\")\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgYo5r2DaCXU"
      },
      "outputs": [],
      "source": [
        "def response(text):\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You have to give short answer for some open-ended question\"},\n",
        "      {\"role\": \"user\", \"content\": text},\n",
        "  ]\n",
        "  prompt = pipeline.tokenizer.apply_chat_template(\n",
        "          messages,\n",
        "          tokenize=False,\n",
        "          add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  terminators = [\n",
        "      pipeline.tokenizer.eos_token_id,\n",
        "      pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  outputs = pipeline(\n",
        "      prompt,\n",
        "      max_new_tokens=256,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=True,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      num_return_sequences = 1\n",
        "  )\n",
        "  return outputs[0][\"generated_text\"][len(prompt):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80oSsDRIg2fS"
      },
      "outputs": [],
      "source": [
        "generated_responses = [{dataset['test']['question'][i]: response(dataset['test']['question'][i])} for i in range(dataset.num_rows['test'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U6fxfUsexhQ"
      },
      "outputs": [],
      "source": [
        "# Save the dictionary as JSON into a file\n",
        "with open(\"/content/drive/MyDrive/topics_in_ai/generated_responses.json\", \"w\") as f:\n",
        "    json.dump(generated_responses, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8WdzFAXe9th"
      },
      "outputs": [],
      "source": [
        "generated_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsEySZHeMY6P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
